Recap:
Week 1: Introduction about supervised learning and unsupervised learning.Understood about Regression and Classification problems under supervised learning; Clustering and Cocktail-party algorithm under unsupervised learning.
Week 2: Linear Regression in one and multiple variables. Cost function and Gradient descent. Feature Normalizations. Normal equation.
Week 3: Binary classification problem. Logistic regression. Sigmoidal function as hypothesis. Advanced optimization algorithm. fminunc() of Octave. Regularization to avoid over-fitting. Introduction to Multiclass classification problem.
Week 4: Introduction to Neural Networks. Layers of a neural network. Calculation of activation values of each layer. Forward Propagation. Representation of logical operators like AND, OR, XNOR, etc with simple neural network. Training multiclass classification by One-VS-All method.
Week 5: Cost function of a neural network. Backpropagation algorithm to find gradient. Using gradient checking. Random initialization to break the symmetry.
Week 6: Machine Learning Diagnostic. Evaluating the hypothesis. Model selection. Recognizing High bias or high variance from learning curves. Debugging depending whether there's high bias or high variance.
Week 7: Support Vector Machine (Large Margin Classifier). Kernels. Gaussian Kernel. Selection of SVM Parameters.
Week 8: Unsupervised learning. Clustering - K Means Algorithm. Dimensionality Reduction-PCA.
